# -*- coding: utf-8 -*-
# --------------------------------------
# @Time    : 2021/10/30 ä¸‹åˆ4:25
# @Author  : Oscar Chen
# @Email   : 530824679@qq.com
# @File    : torch_utils.py
# @Software: PyCharm
# Description : None
# --------------------------------------
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import os                               # ä¸æ“ä½œç³»ç»Ÿè¿›è¡Œäº¤äº’çš„æ¨¡å—
import copy
import torch
import logging                          # æ—¥å¿—åŠŸèƒ½ç”Ÿæˆæ¨¡å—
import platform                         # æä¾›è·å–æ“ä½œç³»ç»Ÿç›¸å…³ä¿¡æ¯çš„æ¨¡å—
logger = logging.getLogger(__name__)

def get_saved_state(model, optimizer, lr_scheduler, epoch, hyp):
    """Get the information to save with checkpoints"""
    if hasattr(model, 'module'):
        model_state_dict = model.module.state_dict()
    else:
        model_state_dict = model.state_dict()
    utils_state_dict = {
        'epoch': epoch,
        'hyp': hyp,
        'optimizer': copy.deepcopy(optimizer.state_dict()),
        'lr_scheduler': copy.deepcopy(lr_scheduler.state_dict())
    }

    return model_state_dict, utils_state_dict

def save_checkpoint(checkpoints_dir, saved_fn, model_state_dict, utils_state_dict, epoch):
    """Save checkpoint every epoch only is best model or after every checkpoint_freq epoch"""
    model_save_path = os.path.join(checkpoints_dir, 'Model_{}_epoch_{}.pth'.format(saved_fn, epoch))
    utils_save_path = os.path.join(checkpoints_dir, 'Utils_{}_epoch_{}.pth'.format(saved_fn, epoch))

    torch.save(model_state_dict, model_save_path)
    torch.save(utils_state_dict, utils_save_path)

    print('save a checkpoint at {}'.format(model_save_path))

def select_device(device='', batch_size=None):
    """
    ç”¨äºé€‰æ‹©æ¨¡å‹è®­ç»ƒçš„è®¾å¤‡ å¹¶è¾“å‡ºæ—¥å¿—ä¿¡æ¯
    :params device: è¾“å…¥çš„è®¾å¤‡  device = 'cpu' or '0' or '0,1,2,3'
    :params batch_size: ä¸€ä¸ªæ‰¹æ¬¡çš„å›¾ç‰‡ä¸ªæ•°
    """
    # s: ä¹‹åè¦åŠ å…¥loggeræ—¥å¿—çš„æ˜¾ç¤ºä¿¡æ¯
    s = f'3DOD ğŸš€ torch {torch.__version__} '  # string
    # å¦‚æœdeviceè¾“å…¥ä¸ºcpu  cpu=True  device.lower(): å°†deviceå­—ç¬¦ä¸²å…¨éƒ¨è½¬ä¸ºå°å†™å­—æ¯
    cpu = device.lower() == 'cpu'
    if cpu:
        # å¦‚æœcpu=True å°±å¼ºåˆ¶(force)ä½¿ç”¨cpu ä»¤torch.cuda.is_available() = False
        os.environ['CUDA_VISIBLE_DEVICES'] = '-1'
    elif device:
        # å¦‚æœè¾“å…¥deviceä¸ä¸ºç©º  device=GPU  ç›´æ¥è®¾ç½® CUDA environment variable = device åŠ å…¥CUDAå¯ç”¨è®¾å¤‡
        os.environ['CUDA_VISIBLE_DEVICES'] = device
        # æ£€æŸ¥cudaçš„å¯ç”¨æ€§ å¦‚æœä¸å¯ç”¨åˆ™ç»ˆæ­¢ç¨‹åº
        assert torch.cuda.is_available(), f'CUDA unavailable, invalid device {device} requested'  # check availability

    # è¾“å…¥deviceä¸ºç©º è‡ªè¡Œæ ¹æ®è®¡ç®—æœºæƒ…å†µé€‰æ‹©ç›¸åº”è®¾å¤‡  å…ˆçœ‹GPU æ²¡æœ‰å°±CPU
    # å¦‚æœcudaå¯ç”¨ ä¸” è¾“å…¥device != cpu åˆ™ cuda=True åæ­£cuda=False
    cuda = not cpu and torch.cuda.is_available()
    if cuda:
        # n: æ‰€æœ‰å¯ç”¨çš„gpuè®¾å¤‡æ•°é‡  device count
        n = torch.cuda.device_count()
        # æ£€æŸ¥æ˜¯å¦æœ‰gpuè®¾å¤‡ ä¸” batch_sizeæ˜¯å¦å¯ä»¥èƒ½è¢«æ˜¾å¡æ•°ç›®æ•´é™¤  check batch_size is divisible by device_count
        if n > 1 and batch_size:
            # å¦‚æœä¸èƒ½åˆ™å…³é—­ç¨‹åº
            assert batch_size % n == 0, f'batch-size {batch_size} not multiple of GPU count {n}'
        # å®šä¹‰ç­‰é•¿çš„ç©ºæ ¼
        space = ' ' * len(s)

        # æ»¡è¶³æ‰€æœ‰æ¡ä»¶ såŠ ä¸Šæ‰€æœ‰æ˜¾å¡çš„ä¿¡æ¯
        for i, d in enumerate(device.split(',') if device else range(n)):
            # p: æ¯ä¸ªå¯ç”¨æ˜¾å¡çš„ç›¸å…³å±æ€§
            p = torch.cuda.get_device_properties(i)
            # æ˜¾ç¤ºä¿¡æ¯såŠ ä¸Šæ¯å¼ æ˜¾å¡çš„å±æ€§ä¿¡æ¯
            s += f"{'' if i == 0 else space}CUDA:{d} ({p.name}, {p.total_memory / 1024 ** 2}MB)\n"  # bytes to MB
    else:
        # cudaä¸å¯ç”¨æ˜¾ç¤ºä¿¡æ¯så°±åŠ ä¸ŠCPU
        s += 'CPU\n'

    # å°†æ˜¾ç¤ºä¿¡æ¯såŠ å…¥loggeræ—¥å¿—æ–‡ä»¶ä¸­
    logger.info(s.encode().decode('ascii', 'ignore') if platform.system() == 'Windows' else s)  # emoji-safe
    # å¦‚æœcudaå¯ç”¨å°±è¿”å›ç¬¬ä¸€å¼ æ˜¾å¡çš„çš„åç§° å¦‚: GeForce RTX 2060 åä¹‹è¿”å›CPUå¯¹åº”çš„åç§°
    return torch.device('cuda:0' if cuda else 'cpu')